# Import necessary libraries
import pandas as pd
import numpy as np
from rapidfuzz import process, fuzz

# Simulate Student Depression Dataset
data_depression = {
    'StudentID': [101, 102, 103, 104, 105],
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Age': [20, 21, 20, 22, 21],
    'Gender': ['F', 'M', 'M', 'M', 'F'],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],
    'SurveyResponse': [
        "I feel overwhelmed with my studies.",
        "I have been very stressed and anxious lately.",
        "I am happy with my academic progress.",
        "I often feel down and unmotivated.",
        "I am satisfied with my social life, but tired."
    ],
    'DepressionScore': [7.5, 8.2, 3.0, 7.8, 4.5]  # Scale 0-10; higher means more depressive symptoms
}
df_depression = pd.DataFrame(data_depression)

# Simulate Student Exam Scores Dataset
data_exam = {
    'StudentID': [201, 202, 203, 204, 205],
    'Age': [20, 21, 20, 22, 21],
    'Gender': ['F', 'M', 'M', 'M', 'F'],
    'City': ['New York City', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],
    'CGPA': [3.8, 2.4, 3.5, 2.3, 3.2],
    'ExamScore': [88, 65, 80, 60, 75]
}
df_exam = pd.DataFrame(data_exam)

# Define a function to fuzzy-match city names
def fuzzy_match(city, choices, score_cutoff=80):
    match = process.extractOne(city, choices, scorer=fuzz.ratio)
    if match and match[1] >= score_cutoff:
        return match[0]
    else:
        return None

# Create a reference list from exam dataset city names
exam_cities = df_exam['City'].unique()

# Apply fuzzy matching to standardize city names in depression dataset
df_depression['MatchedCity'] = df_depression['City'].apply(lambda x: fuzzy_match(x, exam_cities))

# Merge datasets on Age, Gender, and MatchedCity (assuming these are sufficient identifiers)
df_merged = pd.merge(df_depression, df_exam, left_on=['Age', 'Gender', 'MatchedCity'],
                     right_on=['Age', 'Gender', 'City'], how='inner', suffixes=('_dep', '_exam'))

# Display the merged dataset
print("Merged Dataset:")
print(df_merged)

import matplotlib.pyplot as plt
import seaborn as sns

# Set the visual style
sns.set(style="whitegrid")

# Histogram of CGPA from the exam dataset
plt.figure(figsize=(8, 5))
sns.histplot(df_merged['CGPA'], bins=5, kde=True)
plt.title('Distribution of CGPA')
plt.xlabel('CGPA')
plt.ylabel('Frequency')
plt.show()

# Scatter plot: ExamScore vs. CGPA
plt.figure(figsize=(8, 5))
sns.scatterplot(x='CGPA', y='ExamScore', data=df_merged, hue='Gender')
plt.title('Exam Score vs. CGPA')
plt.xlabel('CGPA')
plt.ylabel('Exam Score')
plt.show()

from transformers import pipeline

# Initialize sentiment-analysis pipeline (using Hugging Face's transformer model)
sentiment_analyzer = pipeline("sentiment-analysis")

# Apply sentiment analysis on the SurveyResponse column
df_merged['Sentiment'] = df_merged['SurveyResponse'].apply(lambda text: sentiment_analyzer(text)[0]['label'])

# Display the results
print("Survey Responses with Sentiment Analysis:")
print(df_merged[['Name', 'SurveyResponse', 'Sentiment']])

# Import machine learning libraries
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix

# Create a binary target: 1 if DepressionScore >= 7, else 0
df_merged['Depressed'] = (df_merged['DepressionScore'] >= 7).astype(int)

# Select features (using CGPA and ExamScore as predictors; extend this with more features as needed)
features = ['CGPA', 'ExamScore']
X = df_merged[features]
y = df_merged['Depressed']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# --- Logistic Regression ---
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_logreg))

# --- Random Forest Classifier ---
rf = RandomForestClassifier(random_state=42)
# Optionally, use GridSearchCV for hyperparameter tuning
rf_params = {'n_estimators': [50, 100], 'max_depth': [3, 5, None]}
grid_rf = GridSearchCV(rf, rf_params, cv=3)
grid_rf.fit(X_train, y_train)
y_pred_rf = grid_rf.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

# --- XGBoost Classifier ---
xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb_clf.fit(X_train, y_train)
y_pred_xgb = xgb_clf.predict(X_test)
print("XGBoost Accuracy:", accuracy_score(y_test, y_pred_xgb))

# Evaluate models using F1-score and AUC-ROC as well
for name, preds in zip(["Logistic Regression", "Random Forest", "XGBoost"],
                         [y_pred_logreg, y_pred_rf, y_pred_xgb]):
    print(f"{name} F1-Score: {f1_score(y_test, preds):.2f}")

# Confusion Matrix for the best model (example: Random Forest)
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

import statsmodels.api as sm
import statsmodels.formula.api as smf

# Assume a treatment is assigned to students with CGPA below 2.5
cutoff = 2.5
df_merged['Treatment'] = (df_merged['CGPA'] < cutoff).astype(int)

# For RD analysis, filter data within a narrow bandwidth around the cutoff (e.g., CGPA between 2.0 and 3.0)
bandwidth = 0.5
df_rd = df_merged[(df_merged['CGPA'] >= (cutoff - bandwidth)) & (df_merged['CGPA'] <= (cutoff + bandwidth))]

# Visualize the discontinuity: scatter plot with a fitted regression line
plt.figure(figsize=(8, 5))
sns.scatterplot(x='CGPA', y='ExamScore', data=df_rd, hue='Treatment')
plt.axvline(x=cutoff, color='red', linestyle='--', label='Cutoff')
plt.title('Regression Discontinuity: Exam Score vs. CGPA')
plt.xlabel('CGPA')
plt.ylabel('Exam Score')
plt.legend()
plt.show()

# Perform local linear regression around the cutoff using statsmodels
# Model: ExamScore ~ CGPA + Treatment + (CGPA * Treatment)
rd_formula = 'ExamScore ~ CGPA + Treatment + I(CGPA * Treatment)'
rd_model = smf.ols(rd_formula, data=df_rd).fit()
print("RD Model Summary:")
print(rd_model.summary())
